{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall -y tensorflow tensorflow-gpu tf-keras keras flash-attn\n",
    "%pip install -q torch torchvision\n",
    "%pip install -q transformers accelerate\n",
    "%pip install -q qwen-vl-utils pillow requests\n",
    "%pip install -q pdf2image pymupdf pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Step 1: Import Dependencies for Qwen2.5 Vision-Language Model\n",
    "\n",
    "This cell imports all required libraries for running the Qwen2.5 model, which is a\n",
    "vision-language model that processes both text and images. We use AutoModelForVision2Seq\n",
    "instead of the standard AutoModel because Qwen2.5 is specifically designed for\n",
    "vision-to-sequence tasks (e.g., image captioning, visual question answering).\n",
    "\"\"\"\n",
    "import time\n",
    "import torch\n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "import fitz  # PyMuPDF - Used for PDF processing and image extraction\n",
    "import io\n",
    "import os\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# Verify library versions and hardware availability\n",
    "# This helps ensure compatibility and diagnose potential issues before model loading\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {__import__('transformers').__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Display GPU information if available\n",
    "# GPU acceleration is critical for efficient inference with large vision-language models\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Step 2: Load Qwen2.5 Vision-Language Model\n",
    "\n",
    "This cell loads the model and processor. Only run this cell once per session\n",
    "to avoid redundant loading and memory allocation.\n",
    "\"\"\"\n",
    "\n",
    "checkpoint_path = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "print(\"Loading model from checkpoint...\")\n",
    "\n",
    "# Load the vision-language model with optimized settings\n",
    "# - dtype=torch.bfloat16: Uses BFloat16 precision to reduce memory usage by ~50%\n",
    "#   while maintaining numerical stability better than FP16. Critical for fitting\n",
    "#   large models on consumer GPUs.\n",
    "# - device_map=\"auto\": Automatically distributes model layers across available\n",
    "#   GPU(s) and CPU memory, enabling efficient use of hardware resources.\n",
    "# - trust_remote_code=True: Allows execution of custom modeling code from the\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load the processor which handles tokenization and image preprocessing\n",
    "# The processor ensures inputs are formatted correctly for the model's expected input structure\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Display VRAM usage to monitor memory consumption\n",
    "# This helps identify potential out-of-memory issues and track resource utilization\n",
    "print(f\"Current VRAM allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Step 3: PDF to Images Conversion using PyMuPDF\n",
    "\n",
    "These functions handle PDF processing and image preprocessing for optimal OCR performance.\n",
    "PyMuPDF (fitz) is used because it provides faster rendering and better memory efficiency\n",
    "compared to alternatives like pdf2image, and doesn't require external dependencies like Poppler.\n",
    "\"\"\"\n",
    "\n",
    "def pdf_to_images(pdf_path: str, dpi: int = 300) -> List[Image.Image]:\n",
    "    \"\"\"\n",
    "    Convert each page of a PDF document into a PIL Image.\n",
    "\n",
    "    This function uses PyMuPDF's rendering engine to convert PDF pages to raster images.\n",
    "    Higher DPI values produce better quality but increase memory usage and processing time.\n",
    "    300 DPI is chosen as default because it provides a good balance between quality and\n",
    "    performance for most OCR tasks.\n",
    "\n",
    "    Args:\n",
    "        pdf_path: Absolute or relative path to the PDF file\n",
    "        dpi: Dots per inch for rendering. Standard values are:\n",
    "             - 72: Screen quality (fast, lower quality)\n",
    "             - 150: Acceptable for basic OCR\n",
    "             - 300: High quality for accurate OCR (recommended)\n",
    "             - 600: Very high quality for small text\n",
    "\n",
    "    Returns:\n",
    "        List of PIL Images in RGB format, one image per page\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the PDF file doesn't exist\n",
    "        fitz.FileDataError: If the file is not a valid PDF\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "\n",
    "    print(f\"Converting PDF to images at {dpi} DPI...\")\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "\n",
    "    # Calculate zoom factor from desired DPI\n",
    "    # PyMuPDF uses 72 DPI as base resolution, so we scale relative to that\n",
    "    zoom = dpi / 72.0\n",
    "    mat = fitz.Matrix(zoom, zoom)\n",
    "\n",
    "    try:\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "\n",
    "            # Render page to pixmap (raster image)\n",
    "            # alpha=False removes transparency channel to save memory and ensure RGB output\n",
    "            pix = page.get_pixmap(matrix=mat, alpha=False)\n",
    "\n",
    "            # Convert PyMuPDF pixmap to PIL Image\n",
    "            # This conversion is necessary because the model processor expects PIL Images\n",
    "            img = Image.frombytes(\n",
    "                \"RGB\",\n",
    "                [pix.width, pix.height],\n",
    "                pix.samples\n",
    "            )\n",
    "            images.append(img)\n",
    "\n",
    "            print(f\"  Processed page {page_num + 1}/{len(doc)}: {pix.width}x{pix.height}px\")\n",
    "\n",
    "    finally:\n",
    "        # Ensure document is closed even if an error occurs\n",
    "        # This prevents memory leaks from unclosed file handles\n",
    "        doc.close()\n",
    "\n",
    "    print(f\"Successfully converted {len(images)} pages\")\n",
    "    return images\n",
    "\n",
    "\n",
    "def preprocess_image_for_ocr(\n",
    "    image: Image.Image,\n",
    "    max_size: int = 2048\n",
    ") -> Image.Image:\n",
    "    \"\"\"\n",
    "    Resize images that exceed maximum dimensions to prevent memory issues.\n",
    "\n",
    "    Large images can cause out-of-memory errors during model inference and don't\n",
    "    necessarily improve OCR accuracy. This function downscales oversized images while\n",
    "    maintaining aspect ratio. LANCZOS resampling is used because it provides the best\n",
    "    quality for downscaling, preserving text clarity better than other methods.\n",
    "\n",
    "    Args:\n",
    "        image: Input PIL Image in any mode\n",
    "        max_size: Maximum allowed dimension (width or height) in pixels.\n",
    "                  2048 is chosen as a reasonable upper bound that balances quality\n",
    "                  with memory constraints for most GPUs (typically uses ~4-6GB VRAM)\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed PIL Image, resized if necessary\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "\n",
    "    # Only resize if image exceeds maximum dimension\n",
    "    # This avoids unnecessary processing and potential quality loss for smaller images\n",
    "    if max(width, height) > max_size:\n",
    "        # Calculate scale factor to fit within max_size while preserving aspect ratio\n",
    "        scale = max_size / max(width, height)\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "\n",
    "        # LANCZOS provides highest quality downsampling, critical for preserving text legibility\n",
    "        image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        print(f\"    Image resized: {width}x{height} -> {new_width}x{new_height}\")\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "print(\"PDF processing functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Step 4: OCR Generation with Retry Logic and Confidence Scoring\n",
    "\n",
    "This cell implements a robust OCR pipeline with multiple inference attempts per page\n",
    "and confidence scoring to assess output quality. Confidence scores help identify\n",
    "pages that may need manual review or additional processing.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Generation hyperparameters optimized for OCR tasks\n",
    "TEMPERATURE_SCHEDULE = [0.1, 0.2, 0.3]\n",
    "TOP_P_THRESHOLD = 0.95\n",
    "REPETITION_PENALTY = 1.1\n",
    "\n",
    "\n",
    "def calculate_confidence_scores(scores, generated_ids) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate various confidence metrics from model generation scores.\n",
    "\n",
    "    Confidence scores help assess the reliability of OCR output. Lower confidence\n",
    "    may indicate poor image quality, unusual fonts, or model uncertainty.\n",
    "\n",
    "    Args:\n",
    "        scores: Tuple of tensors containing logits for each generated token\n",
    "        generated_ids: The generated token IDs (1D tensor)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with confidence metrics:\n",
    "            - mean_probability: Average probability across all tokens (0-1)\n",
    "            - mean_log_probability: Average log probability (more numerically stable)\n",
    "            - perplexity: Model's uncertainty (lower is better)\n",
    "            - min_probability: Lowest token probability (identifies uncertain tokens)\n",
    "    \"\"\"\n",
    "    if not scores or len(scores) == 0:\n",
    "        return {\n",
    "            'mean_probability': None,\n",
    "            'mean_log_probability': None,\n",
    "            'perplexity': None,\n",
    "            'min_probability': None\n",
    "        }\n",
    "\n",
    "    # Convert logits to probabilities for each token position\n",
    "    # Logits are raw model outputs; softmax converts them to probability distributions\n",
    "    token_probs = []\n",
    "    for i, logits in enumerate(scores):\n",
    "        # Apply softmax to get probability distribution over vocabulary\n",
    "        probs = F.softmax(logits[0], dim=-1)\n",
    "\n",
    "        # Get probability of the actual generated token\n",
    "        token_id = generated_ids[i].item()\n",
    "        token_prob = probs[token_id].item()\n",
    "        token_probs.append(token_prob)\n",
    "\n",
    "    token_probs = np.array(token_probs)\n",
    "\n",
    "    # Calculate various confidence metrics\n",
    "    # Mean probability: Simple average, intuitive but can be skewed by very low values\n",
    "    mean_prob = float(np.mean(token_probs))\n",
    "\n",
    "    # Log probability: More stable for very small probabilities, commonly used in NLP\n",
    "    log_probs = np.log(token_probs + 1e-10)  # Add epsilon to avoid log(0)\n",
    "    mean_log_prob = float(np.mean(log_probs))\n",
    "\n",
    "    # Perplexity: Exponential of negative mean log probability\n",
    "    # Intuition: \"How surprised is the model?\" Lower perplexity = higher confidence\n",
    "    # Typical range: 1.0 (perfect) to 100+ (very uncertain)\n",
    "    perplexity = float(np.exp(-mean_log_prob))\n",
    "\n",
    "    # Minimum probability: Identifies the least confident token\n",
    "    # Useful for spotting specific problem areas in the output\n",
    "    min_prob = float(np.min(token_probs))\n",
    "\n",
    "    return {\n",
    "        'mean_probability': mean_prob,\n",
    "        'mean_log_probability': mean_log_prob,\n",
    "        'perplexity': perplexity,\n",
    "        'min_probability': min_prob\n",
    "    }\n",
    "\n",
    "\n",
    "def ocr_with_retry(\n",
    "    image: Image.Image,\n",
    "    page_num: int = 1,\n",
    "    num_attempts: int = 3,\n",
    "    max_new_tokens: int = 2048,\n",
    "    use_cot: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Perform OCR on a single image with multiple attempts, temperature variations,\n",
    "    and confidence scoring.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image to perform OCR on\n",
    "        page_num: Page number for logging and result tracking\n",
    "        num_attempts: Number of OCR attempts with different temperatures\n",
    "        max_new_tokens: Maximum tokens to generate\n",
    "        use_cot: Whether to use Chain-of-Thought prompting\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing page results with confidence scores for each attempt\n",
    "    \"\"\"\n",
    "\n",
    "    if use_cot:\n",
    "        prompt = \"\"\"Extract all text from this image with perfect accuracy. Let's work systematically:\n",
    "\n",
    "1. First, identify the document structure (headings, paragraphs, tables, lists)\n",
    "2. Then, read each section carefully from top to bottom, left to right\n",
    "3. Preserve formatting, line breaks, and special characters\n",
    "4. Double-check numbers, dates, and proper nouns\n",
    "5. Finally, output the complete text exactly as shown\n",
    "\n",
    "Please provide the full text transcription:\"\"\"\n",
    "    else:\n",
    "        prompt = \"Read and transcribe all text from this image exactly as shown, preserving formatting and structure.\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    all_responses = []\n",
    "\n",
    "    print(f\"\\nPage {page_num} - Running {num_attempts} OCR attempts...\")\n",
    "\n",
    "    for i in range(num_attempts):\n",
    "        temp = TEMPERATURE_SCHEDULE[i % len(TEMPERATURE_SCHEDULE)]\n",
    "        print(f\"  Attempt [{i+1}/{num_attempts}] (temperature={temp})...\", end=\" \")\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        try:\n",
    "            with torch.inference_mode():\n",
    "                # Enable score output to get token probabilities\n",
    "                # return_dict_in_generate=True provides structured output with scores\n",
    "                # output_scores=True includes logits for each generated token\n",
    "                generation_output = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    temperature=temp,\n",
    "                    top_p=TOP_P_THRESHOLD,\n",
    "                    do_sample=temp > 0,\n",
    "                    repetition_penalty=REPETITION_PENALTY,\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_scores=True\n",
    "                )\n",
    "\n",
    "            # Extract generated token IDs\n",
    "            generated_ids = generation_output.sequences\n",
    "\n",
    "            # Trim input tokens from output\n",
    "            generated_ids_trimmed = [\n",
    "                out_ids[len(in_ids):]\n",
    "                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "\n",
    "            # Decode tokens to text\n",
    "            output_text = processor.batch_decode(\n",
    "                generated_ids_trimmed,\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=False\n",
    "            )[0]\n",
    "\n",
    "            elapsed = time.time() - start\n",
    "            char_count = len(output_text)\n",
    "            word_count = len(output_text.split())\n",
    "\n",
    "            # Calculate confidence scores from generation scores\n",
    "            # Pass the 1D tensor directly (not wrapped in a list)\n",
    "            confidence = calculate_confidence_scores(\n",
    "                generation_output.scores,\n",
    "                generated_ids_trimmed[0]  # This is already a 1D tensor\n",
    "            )\n",
    "\n",
    "            all_responses.append({\n",
    "                'attempt': i + 1,\n",
    "                'text': output_text,\n",
    "                'temperature': temp,\n",
    "                'time': elapsed,\n",
    "                'chars': char_count,\n",
    "                'words': word_count,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "\n",
    "            # Display confidence in output\n",
    "            conf_display = f\"confidence={confidence['mean_probability']:.3f}\" if confidence['mean_probability'] else \"confidence=N/A\"\n",
    "            print(f\"Success - {char_count} chars, {conf_display} ({elapsed:.1f}s)\")\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed - {str(e)}\")\n",
    "            # Print more detailed error for debugging\n",
    "            import traceback\n",
    "            print(f\"  Error details: {traceback.format_exc()}\")\n",
    "            continue\n",
    "\n",
    "    if not all_responses:\n",
    "        return {\"error\": f\"All OCR attempts failed for page {page_num}\"}\n",
    "\n",
    "    # Select best response based on both length and confidence\n",
    "    # Prioritize length but consider confidence as a secondary factor\n",
    "    best = max(all_responses, key=lambda x: x['chars'])\n",
    "\n",
    "    return {\n",
    "        'page_num': page_num,\n",
    "        'best_response': best,\n",
    "        'all_responses': all_responses,\n",
    "        'total_attempts': len(all_responses)\n",
    "    }\n",
    "\n",
    "\n",
    "def ocr_pdf(\n",
    "    pdf_path: str,\n",
    "    dpi: int = 300,\n",
    "    attempts_per_page: int = 3,\n",
    "    use_cot: bool = True,\n",
    "    max_pages: int = None\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Perform OCR on an entire PDF document with retry logic and confidence scoring per page.\n",
    "\n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        dpi: Resolution for PDF rendering\n",
    "        attempts_per_page: Number of OCR attempts per page\n",
    "        use_cot: Whether to use Chain-of-Thought prompting\n",
    "        max_pages: Optional limit on pages to process\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with results including per-page confidence scores\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"PDF OCR WITH RETRY LOGIC AND CONFIDENCE SCORING\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    images = pdf_to_images(pdf_path, dpi=dpi)\n",
    "\n",
    "    if max_pages:\n",
    "        images = images[:max_pages]\n",
    "        print(f\"Processing first {max_pages} pages only (limit applied)\")\n",
    "\n",
    "    total_pages = len(images)\n",
    "    print(f\"Total pages to process: {total_pages}\\n\")\n",
    "\n",
    "    all_results = []\n",
    "    total_start = time.time()\n",
    "\n",
    "    for i, image in enumerate(images, 1):\n",
    "        processed_img = preprocess_image_for_ocr(image)\n",
    "\n",
    "        result = ocr_with_retry(\n",
    "            image=processed_img,\n",
    "            page_num=i,\n",
    "            num_attempts=attempts_per_page,\n",
    "            max_new_tokens=2048,\n",
    "            use_cot=use_cot\n",
    "        )\n",
    "\n",
    "        all_results.append(result)\n",
    "\n",
    "        if 'best_response' in result:\n",
    "            best = result['best_response']\n",
    "            conf = best['confidence']\n",
    "            conf_str = f\"{conf['mean_probability']:.3f}\" if conf['mean_probability'] else \"N/A\"\n",
    "            print(f\"  Page {i}/{total_pages} completed: \"\n",
    "                  f\"{best['chars']} characters, confidence={conf_str}\\n\")\n",
    "        else:\n",
    "            print(f\"  Page {i}/{total_pages} failed: {result.get('error', 'Unknown error')}\\n\")\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "\n",
    "    full_text = \"\\n\\n\" + \"\\n\\n\".join([\n",
    "        f\"{'=' * 80}\\nPAGE {r['page_num']}\\n{'=' * 80}\\n{r['best_response']['text']}\"\n",
    "        for r in all_results if 'best_response' in r\n",
    "    ])\n",
    "\n",
    "    total_chars = sum(\n",
    "        r['best_response']['chars']\n",
    "        for r in all_results\n",
    "        if 'best_response' in r\n",
    "    )\n",
    "\n",
    "    # Calculate average confidence across all pages\n",
    "    avg_confidence = np.mean([\n",
    "        r['best_response']['confidence']['mean_probability']\n",
    "        for r in all_results\n",
    "        if 'best_response' in r and r['best_response']['confidence']['mean_probability'] is not None\n",
    "    ]) if all_results else None\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PDF OCR COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Pages processed: {total_pages}\")\n",
    "    print(f\"Total characters: {total_chars:,}\")\n",
    "    print(f\"Average confidence: {avg_confidence:.3f}\" if avg_confidence else \"Average confidence: N/A\")\n",
    "    print(f\"Total time: {total_time:.1f}s (average: {total_time/total_pages:.1f}s per page)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    return {\n",
    "        'pages': all_results,\n",
    "        'full_text': full_text,\n",
    "        'total_pages': total_pages,\n",
    "        'total_chars': total_chars,\n",
    "        'total_time': total_time,\n",
    "        'avg_confidence': avg_confidence\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"OCR functions with retry logic and confidence scoring defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Step 6: Batch Process PDFs in Directory Structure\n",
    "\n",
    "This cell implements recursive directory traversal to process all PDFs found in\n",
    "a folder hierarchy. Results are saved alongside source files to maintain organization.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import traceback\n",
    "\n",
    "\n",
    "def find_pdf_files(root_directory: str, skip_processed: bool = True) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Recursively find all PDF files in a directory and its subdirectories.\n",
    "\n",
    "    This function traverses the entire directory tree to locate PDFs while optionally\n",
    "    skipping files that have already been processed (i.e., have corresponding .txt files).\n",
    "    This prevents redundant processing in subsequent runs.\n",
    "\n",
    "    Args:\n",
    "        root_directory: Path to the root directory to search\n",
    "        skip_processed: If True, skip PDFs that already have corresponding .txt output files.\n",
    "                       This is useful for resuming interrupted batch jobs.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: (pdf_path, output_txt_path) for each PDF to process\n",
    "    \"\"\"\n",
    "    pdf_files = []\n",
    "\n",
    "    # Validate root directory exists\n",
    "    if not os.path.exists(root_directory):\n",
    "        raise FileNotFoundError(f\"Directory not found: {root_directory}\")\n",
    "\n",
    "    print(f\"Scanning directory: {root_directory}\")\n",
    "\n",
    "    # os.walk recursively yields (dirpath, dirnames, filenames) for each directory\n",
    "    # This is more efficient than recursive function calls for deep hierarchies\n",
    "    for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "        for filename in filenames:\n",
    "            # Case-insensitive PDF detection to handle .PDF, .pdf, .Pdf, etc.\n",
    "            if filename.lower().endswith('.pdf'):\n",
    "                pdf_path = os.path.join(dirpath, filename)\n",
    "\n",
    "                # Generate output filename by replacing .pdf extension with .txt\n",
    "                # This keeps the output in the same directory as the source\n",
    "                output_filename = os.path.splitext(filename)[0] + '_ocr.txt'\n",
    "                output_path = os.path.join(dirpath, output_filename)\n",
    "\n",
    "                # Skip if already processed (unless user wants to reprocess)\n",
    "                if skip_processed and os.path.exists(output_path):\n",
    "                    print(f\"  Skipping (already processed): {pdf_path}\")\n",
    "                    continue\n",
    "\n",
    "                pdf_files.append((pdf_path, output_path))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF(s) to process\")\n",
    "    return pdf_files\n",
    "\n",
    "\n",
    "def process_pdf_batch(\n",
    "    root_directory: str,\n",
    "    dpi: int = 300,\n",
    "    attempts_per_page: int = 3,\n",
    "    use_cot: bool = True,\n",
    "    max_pages: int = None,\n",
    "    skip_processed: bool = True,\n",
    "    save_detailed: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Process all PDFs found in a directory tree with OCR.\n",
    "\n",
    "    This function orchestrates batch OCR processing across multiple files. It handles\n",
    "    errors gracefully so that one failed PDF doesn't stop the entire batch. Progress\n",
    "    is tracked and reported to help monitor long-running jobs.\n",
    "\n",
    "    Args:\n",
    "        root_directory: Root directory to search for PDFs\n",
    "        dpi: Resolution for PDF rendering\n",
    "        attempts_per_page: Number of OCR attempts per page\n",
    "        use_cot: Whether to use Chain-of-Thought prompting\n",
    "        max_pages: Optional limit on pages per PDF (useful for testing)\n",
    "        skip_processed: Skip PDFs that already have output files\n",
    "        save_detailed: If True, also save detailed JSON output with all attempts\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with batch processing statistics\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"BATCH PDF OCR PROCESSING\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Find all PDFs to process\n",
    "    pdf_files = find_pdf_files(root_directory, skip_processed=skip_processed)\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(\"\\nNo PDFs found to process.\")\n",
    "        return {\n",
    "            'total_files': 0,\n",
    "            'successful': 0,\n",
    "            'failed': 0,\n",
    "            'skipped': 0\n",
    "        }\n",
    "\n",
    "    # Track batch statistics\n",
    "    total_files = len(pdf_files)\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    failed_files = []\n",
    "    batch_start = time.time()\n",
    "\n",
    "    print(f\"\\nProcessing {total_files} PDF file(s)...\\n\")\n",
    "\n",
    "    # Process each PDF individually\n",
    "    # Using enumerate for progress tracking\n",
    "    for idx, (pdf_path, output_path) in enumerate(pdf_files, 1):\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"FILE {idx}/{total_files}: {os.path.basename(pdf_path)}\")\n",
    "        print(f\"Location: {os.path.dirname(pdf_path)}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        try:\n",
    "            # Run OCR on the PDF\n",
    "            # Each file is processed independently to isolate errors\n",
    "            results = ocr_pdf(\n",
    "                pdf_path=pdf_path,\n",
    "                dpi=dpi,\n",
    "                attempts_per_page=attempts_per_page,\n",
    "                use_cot=use_cot,\n",
    "                max_pages=max_pages\n",
    "            )\n",
    "\n",
    "            # Save text output to the same directory as source PDF\n",
    "            # This maintains the organizational structure of the input\n",
    "            save_results(\n",
    "                results=results,\n",
    "                filename=output_path,\n",
    "                include_metadata=True\n",
    "            )\n",
    "\n",
    "            # Optionally save detailed JSON output with all metadata\n",
    "            # Useful for quality analysis or when you need access to all attempts\n",
    "            if save_detailed:\n",
    "                detailed_path = output_path.replace('_ocr.txt', '_ocr_detailed.json')\n",
    "                save_detailed_results(results, filename=detailed_path)\n",
    "\n",
    "            successful += 1\n",
    "            print(f\"\\nFile {idx}/{total_files} completed successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log error but continue processing remaining files\n",
    "            # This ensures one problematic PDF doesn't halt the entire batch\n",
    "            failed += 1\n",
    "            failed_files.append({\n",
    "                'file': pdf_path,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "            print(f\"\\nError processing {pdf_path}:\")\n",
    "            print(f\"  {str(e)}\")\n",
    "            print(\"\\nFull traceback:\")\n",
    "            print(traceback.format_exc())\n",
    "            print(\"\\nContinuing with next file...\")\n",
    "\n",
    "        # Clear GPU memory between files to prevent accumulation\n",
    "        # This is critical for processing larg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = process_pdf_batch(\n",
    "    root_directory='reports',\n",
    "    dpi=300,\n",
    "    attempts_per_page=3,\n",
    "    skip_processed=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
